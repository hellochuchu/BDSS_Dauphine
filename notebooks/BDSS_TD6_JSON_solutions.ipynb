{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lucasgneccoh/BDSS_Dauphine/blob/main/BDSS_TD6_JSON_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-9rovwlHP_X"
   },
   "source": [
    "# Bases de données semi-structurées - TD 6\n",
    "\n",
    "Welcome to the support Python notebook for this TD. This notebook follows the paper version of the TD. \n",
    "\n",
    "The idea is to make the same exercises in a more interactive way, practice some Python and also discover or practice with Google Colab notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A0I1eANdH1u"
   },
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8i6vqq1FuQh"
   },
   "source": [
    "## `json` library examples\n",
    "Here we show how to read and write JSON files using the `json` library.\n",
    "\n",
    "Example file is taken from \n",
    "\n",
    "https://json-schema.org/learn/getting-started-step-by-step.html#properties-deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SwLF3qxcFmqQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Create a JSON object and write it in a file\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "# Take the json example in Python format (a dictionary)\n",
    "# In Python, the equivalent of a JSON object is a dict\n",
    "# A JSON array is a list\n",
    "json_object = {\n",
    "                \"productId\": 1,\n",
    "                \"productName\": \"An ice sculpture\",\n",
    "                \"price\": 12.50,\n",
    "                \"tags\": [ \"cold\", \"ice\" ],\n",
    "                \"dimensions\": {\n",
    "                    \"length\": 7.0,\n",
    "                    \"width\": 12.0,\n",
    "                    \"height\": 9.5\n",
    "                    },\n",
    "                \"warehouseLocation\": {\n",
    "                    \"latitude\": -78.75,\n",
    "                    \"longitude\": 20.4\n",
    "                    }\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9p-mFB7CcUY7",
    "outputId": "694e00d6-d53a-4f6e-a762-44ad9d6b6f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON object as a string:\n",
      " <class 'str'> {\"productId\": 1, \"productName\": \"An ice sculpture\", \"price\": 12.5, \"tags\": [\"cold\", \"ice\"], \"dimensions\": {\"length\": 7.0, \"width\": 12.0, \"height\": 9.5}, \"warehouseLocation\": {\"latitude\": -78.75, \"longitude\": 20.4}}\n",
      "JSON object read from a string:\n",
      " <class 'dict'> {'productId': 1, 'productName': 'An ice sculpture', 'price': 12.5, 'tags': ['cold', 'ice'], 'dimensions': {'length': 7.0, 'width': 12.0, 'height': 9.5}, 'warehouseLocation': {'latitude': -78.75, 'longitude': 20.4}}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    First lets print the object as a string in JSON format\n",
    "    Then read a JSON object from a string\n",
    "    Use functions json.loads and json.dumps\n",
    "\n",
    "'''\n",
    "s = json.dumps(json_object)\n",
    "print(\"JSON object as a string:\\n\", type(s), s)\n",
    "\n",
    "json_object = None\n",
    "json_object = json.loads(s)\n",
    "print(\"JSON object read from a string:\\n\", type(json_object), json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HSs28a6pcPyW"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Lets write this to a file called myjson.json\n",
    "    Use function json.dump\n",
    "'''\n",
    "\n",
    "filename = \"myjson.json\"\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(json_object, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9tYIY3kX1PW",
    "outputId": "56fc251d-6f29-4020-dcdb-525588d69766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"productId\": 1, \"productName\": \"An ice sculpture\", \"price\": 12.5, \"tags\": [\"cold\", \"ice\"], \"dimensions\": {\"length\": 7.0, \"width\": 12.0, \"height\": 9.5}, \"warehouseLocation\": {\"latitude\": -78.75, \"longitude\": 20.4}}"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Now see the content of the file as it is\n",
    "'''\n",
    "!cat myjson.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9vRlDcKYHRJ",
    "outputId": "4ca84e27-4373-4b8e-dc3a-ff43badb7286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json_object variable is of type: <class 'dict'>\n",
      "\n",
      "{'productId': 1, 'productName': 'An ice sculpture', 'price': 12.5, 'tags': ['cold', 'ice'], 'dimensions': {'length': 7.0, 'width': 12.0, 'height': 9.5}, 'warehouseLocation': {'latitude': -78.75, 'longitude': 20.4}}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Lets read it in a Python object to see what it gives \n",
    "    Use function json.load\n",
    "'''\n",
    "json_object = None\n",
    "with open(filename, \"r\") as f:\n",
    "    json_object = json.load(f)\n",
    "\n",
    "\n",
    "print(f\"The json_object variable is of type: {type(json_object)}\")\n",
    "print()\n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8CGVXpAdKwF"
   },
   "source": [
    "## `jsonschema` library\n",
    "This library allows to validate JSON objects against a JSONSchema\n",
    "\n",
    "Again we folow the example given in \n",
    "\n",
    "https://json-schema.org/learn/getting-started-step-by-step.html#properties-deeper\n",
    "\n",
    "\n",
    "`jsonschema` documentation available at\n",
    "\n",
    "https://python-jsonschema.readthedocs.io/en/stable/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BbDcEtvDeTRu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install jsonschema\n",
    "from jsonschema import Draft7Validator, RefResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MMC5IRjWdnql"
   },
   "outputs": [],
   "source": [
    "schemaProducts =  {\n",
    "  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "  \"$id\": \"example.com.product.schema.json\",\n",
    "  \"title\": \"Product\",\n",
    "  \"description\": \"A product from Acme's catalog\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"productId\": {\n",
    "      \"description\": \"The unique identifier for a product\",\n",
    "      \"type\": \"integer\"\n",
    "    },\n",
    "    \"productName\": {\n",
    "      \"description\": \"Name of the product\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"price\": {\n",
    "      \"description\": \"The price of the product\",\n",
    "      \"type\": \"number\",\n",
    "      \"exclusiveMinimum\": 0\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"description\": \"Tags for the product\",\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"minItems\": 1,\n",
    "      \"uniqueItems\": True\n",
    "    },\n",
    "    \"dimensions\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"length\": {\n",
    "          \"type\": \"number\"\n",
    "        },\n",
    "        \"width\": {\n",
    "          \"type\": \"number\"\n",
    "        },\n",
    "        \"height\": {\n",
    "          \"type\": \"number\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [ \"length\", \"width\", \"height\" ]\n",
    "    },\n",
    "    \"warehouseLocation\": {\n",
    "      \"description\": \"Coordinates of the warehouse where the product is located.\",\n",
    "      \"$ref\": \"example.com.geographical-location.schema.json\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [ \"productId\", \"productName\", \"price\" ]\n",
    "}\n",
    "\n",
    "schemaGeo = {\n",
    "  \"$id\": \"example.com.geographical-location.schema.json\",\n",
    "  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "  \"title\": \"Longitude and Latitude\",\n",
    "  \"description\": \"A geographical coordinate on a planet (most commonly Earth).\",\n",
    "  \"required\": [ \"latitude\", \"longitude\" ],\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"latitude\": {\n",
    "      \"type\": \"number\",\n",
    "      \"minimum\": -90,\n",
    "      \"maximum\": 90\n",
    "    },\n",
    "    \"longitude\": {\n",
    "      \"type\": \"number\",\n",
    "      \"minimum\": -180,\n",
    "      \"maximum\": 180\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "json.dump(schemaProducts, open(\"schemaProducts.json\", \"w\") )\n",
    "json.dump(schemaGeo, open(\"schemaGeo.json\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Lm5vj_AdsSx",
    "outputId": "106c25b0-027a-4475-ea83-0628672876bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is valid!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Let's see if the example json object we worked with follows the schema or not\n",
    "'''\n",
    "schemaProducts, schemaGeo, json_object = None, None, None\n",
    "json_object = json.load(open(\"myjson.json\"))\n",
    "schemaProducts = json.load(open(\"schemaProducts.json\"))\n",
    "schemaGeo = json.load(open(\"schemaGeo.json\"))\n",
    "\n",
    "\n",
    "schema_store = {\n",
    "    schemaProducts['$id'] : schemaProducts,\n",
    "    schemaGeo['$id'] : schemaGeo,\n",
    "}\n",
    "\n",
    "# Create a resolver to work with local files and avoid fetching URLs\n",
    "resolver = RefResolver.from_schema(schemaProducts, store=schema_store)\n",
    "\n",
    "validator = Draft7Validator(schemaProducts, resolver=resolver)\n",
    "\n",
    "try:\n",
    "    validator.validate(json_object)\n",
    "    print(\"File is valid!\")\n",
    "except Exception as e:\n",
    "    print(\"File was not validated correctly. Here are the catched exceptions\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMoWnHXKlnHb",
    "outputId": "8a4a01d3-a841-4339-8e1a-5409beeef99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was not validated correctly. Here are the catched exceptions\n",
      "\n",
      "'Hello' is not of type 'integer'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['productId']:\n",
      "    {'description': 'The unique identifier for a product',\n",
      "     'type': 'integer'}\n",
      "\n",
      "On instance['productId']:\n",
      "    'Hello'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Let's see what happens when we do not follow the schema\n",
    "'''\n",
    "\n",
    "json_object['warehouseLocation']['latitude'] = 120\n",
    "json_object['productId'] = 'Hello'\n",
    "\n",
    "try:\n",
    "    validator.validate(json_object)\n",
    "    print(\"File is valid!\")\n",
    "except Exception as e:\n",
    "    print(\"File was not validated correctly. Here are the catched exceptions\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwMWWwBmnFTU"
   },
   "source": [
    "# Excercise 1: Write a schema\n",
    "\n",
    "To begin with, we are going to create a schema for a very simple situation we already know well... films!\n",
    "\n",
    "Take the original DTD for the FILMS database and make it a JSON schema. \n",
    "\n",
    "**You can change some things if you want to make it more complex or realistic, as long as the Schema is well written and makes sense.**\n",
    "\n",
    "***NOTE: Be careful, there might be some structural changes needed***\n",
    "\n",
    "Here is the DTD\n",
    "\n",
    "```\n",
    "    <!ELEMENT FILMS (FILM+, ARTISTE+)>\n",
    "    <!ELEMENT FILM (TITRE, GENRE, PAYS, MES, ROLES, RESUME?)>\n",
    "    <!ELEMENT TITRE (#PCDATA)>\n",
    "    <!ATTLIST FILM Annee CDATA #REQUIRED>\n",
    "    <!ELEMENT GENRE (#PCDATA)>\n",
    "    <!ELEMENT PAYS (#PCDATA)>\n",
    "    <!ELEMENT MES (#PCDATA)>\n",
    "    <!ATTLIST MES id_mes IDREF #IMPLIED>\n",
    "    <!ELEMENT ROLES (ROLE*)>\n",
    "    <!ELEMENT ROLE (PRENOM, NOM, INTITULE)>\n",
    "    <!ELEMENT PRENOM (#PCDATA)>\n",
    "    <!ELEMENT NOM (#PCDATA)>\n",
    "    <!ELEMENT INTITULE (#PCDATA)>\n",
    "    <!ELEMENT RESUME (#PCDATA)>\n",
    "    <!ELEMENT ARTISTE (ACTNOM, ACTPNOM, ANNEENAISS)>\n",
    "    <!ATTLIST ARTISTE id_art ID #REQUIRED>\n",
    "    <!ELEMENT ACTNOM (#PCDATA)>\n",
    "    <!ELEMENT ACTPNOM (#PCDATA)>\n",
    "    <!ELEMENT ANNEENAISS (#PCDATA)>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ez0VlsI9tj6V",
    "outputId": "8679e5e8-ee9e-4114-a83a-0122182eacc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-22 11:22:52--  https://raw.githubusercontent.com/lucasgneccoh/BDSS_Dauphine/main/data/films.xml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43462 (42K) [text/plain]\n",
      "Saving to: ‘films.xml.1’\n",
      "\n",
      "films.xml.1         100%[===================>]  42,44K  --.-KB/s    in 0,004s  \n",
      "\n",
      "2022-02-22 11:22:52 (10,3 MB/s) - ‘films.xml.1’ saved [43462/43462]\n",
      "\n",
      "{'Comédie', 'Western', 'Policier', 'Thriller', 'Suspense', 'Drame', 'Fantastique', 'Dessin animé', 'Science-fiction', 'Guerre', 'Documentaire', 'Horreur', 'Action'}\n",
      "{'FR', 'JP', 'USA'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Get all the genres to create a good schema using SAX\n",
    "'''\n",
    "from lxml import etree\n",
    "import re\n",
    "from xml.dom.minidom import parse\n",
    "import xml.sax\n",
    "\n",
    "class GetTextInsideTag(xml.sax.ContentHandler):\n",
    "    def __init__(self, tag = None):\n",
    "        super().__init__()\n",
    "        self.tag = tag\n",
    "        self.reading = False\n",
    "        self.buffer = []\n",
    "        self.result = []\n",
    "        \n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if not self.tag is None and name == self.tag:\n",
    "            self.reading = True\n",
    "        return\n",
    "\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if self.buffer:\n",
    "            # If something was read, then add it to results\n",
    "            # before reseting the buffer\n",
    "            self.result.append(' '.join(self.buffer))\n",
    "        self.reading = False\n",
    "        self.buffer = []\n",
    "        return\n",
    "\n",
    "    def characters(self, content):\n",
    "        # When text is encountered\n",
    "        # print(\"Characters '\" + content + \"'\")\n",
    "        if self.reading: self.buffer.append(content)\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "!wget \"https://raw.githubusercontent.com/lucasgneccoh/BDSS_Dauphine/main/data/films.xml\"\n",
    "path = \"films.xml\"\n",
    "\n",
    "\n",
    "f = open(path)\n",
    "handler = GetTextInsideTag(tag = \"GENRE\")\n",
    "xml.sax.parse(f, handler)\n",
    "unique_genres = set(handler.result)\n",
    "print(unique_genres)\n",
    "\n",
    "f = open(path)\n",
    "handler = GetTextInsideTag(tag = \"PAYS\")\n",
    "xml.sax.parse(f, handler)\n",
    "unique_pays = set(handler.result)\n",
    "print(unique_pays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "8TCrjDK_n5R-"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    My proposed solution is structured like this:\n",
    "        - FILMS, the root, is an object containing two arrays: arrFilms and arrArtistes\n",
    "        - FILM is an object that represents one film\n",
    "        - ARTISTE is an object that represents one artist\n",
    "'''\n",
    "\n",
    "\n",
    "schemaRole = {\n",
    "    \"$id\": \"dauphine.bdss.role\",\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"title\": \"Film role\",\n",
    "    \"description\": \"A role played in a film by an artist.\",\n",
    "    \"required\": [ \"NOM\", \"PRENOM\"],\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"NOM\": {\n",
    "            \"description\": \"Last name of the artist\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "        \"PRENOM\": {\n",
    "            \"description\": \"Name of the artist\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"INTITULE\": {\n",
    "            \"description\": \"Name of the character in the film\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "schemaFilmsObject = {\n",
    "    \"$id\": \"dauphine.bdss.film\",\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"title\": \"Film object\",\n",
    "    \"description\": \"Object representing one single film.\",\n",
    "    \"required\": [\"Annee\", \"TITRE\", \"MES\", \"ROLES\"],\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Anne\": {\n",
    "            \"description\": \"Integer containing the year of release of the film\",\n",
    "            \"type\" : \"number\",\n",
    "            \"minimum\" : 1880,\n",
    "            \"maximum\" : 2022\n",
    "        },\n",
    "        \"TITRE\": {\n",
    "            \"description\": \"Object representing the title of the film and making explicit the language and other attributes of the title\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"title\": {\n",
    "                    \"description\": \"The actual title of the film\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"lang\":{\n",
    "                    \"description\": \"Language tag representing the language of the title\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"note\":{\n",
    "                    \"description\": \"Any observation about the title, like its origin, whether it is the official one or not, etc\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"title\", \"lang\"]\n",
    "        },\n",
    "        \"GENRE\": {\n",
    "            \"description\": \"The genre used to tag this film\",\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": list(unique_genres)\n",
    "        },\n",
    "        \"PAYS\": {\n",
    "            \"description\": \"The country of the film, whatever that means\",\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": list(unique_pays)\n",
    "        },\n",
    "        \"MES\": {\n",
    "            \"description\": \"The artist_id of the director of the film\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"ROLES\": {\n",
    "            \"description\": \"Array of the roles in the movie\",\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"description\": \"A role is made of the name and last name of the artist that played the role and the name of the played character\",\n",
    "                \"$ref\": \"dauphine.bdss.role\"\n",
    "            }\n",
    "        },\n",
    "        \"RESUME\": {\n",
    "            \"description\": \"A short description of the film. make it interesting!\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "schemaArtistObject = {\n",
    "    \"$id\": \"dauphine.bdss.artiste\",\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"title\": \"Film object\",\n",
    "    \"description\": \"Object representing one single artist.\",\n",
    "    \"required\": [\"id_art\", \"ACTNOM\", \"ACTPNOM\"],\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"id_art\" : {\n",
    "            \"description\" : \"Unique identifier of the artist in the database\",\n",
    "            \"type\" : \"string\"\n",
    "        },\n",
    "        \"ACTNOM\": {\n",
    "            \"description\": \"Last name of the artist\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"ACTPNOM\": {\n",
    "            \"description\": \"Name of the artist\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"ANNEENAISS\": {\n",
    "            \"description\": \"Name of the character in the film\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "schemaFilmsDatabase = {\n",
    "    \"$id\": \"dauphine.bdss.filmsDatabase\",\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"title\": \"Our beloved films database\",\n",
    "    \"description\": \"A film database that was once scrapped from the internet.\",\n",
    "    \"required\": [ \"arrFilms\", \"arrArtistes\" ],\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"arrFilms\": {\n",
    "            \"description\": \"The array containing all the films\",\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"description\": \"Object of type film\",\n",
    "                \"$ref\": \"dauphine.bdss.film\"\n",
    "            },\n",
    "            \"minItems\": 1\n",
    "        },\n",
    "        \"arrArtistes\": {\n",
    "            \"description\": \"The array containing all the artists\",\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"description\": \"Object of type artiste\",\n",
    "                \"$ref\": \"dauphine.bdss.artiste\"\n",
    "            },\n",
    "            \"minItems\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Save schemas\n",
    "json.dump(schemaRole, open('schemaRole.json', 'w'))\n",
    "json.dump(schemaFilmsObject, open('schemaFilmsObject.json', 'w'))\n",
    "json.dump(schemaArtistObject, open('schemaArtistObject.json', 'w'))\n",
    "json.dump(schemaFilmsDatabase, open('schemaFilmsDatabase.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ3hOsDu4t3Q"
   },
   "source": [
    "# Excercise 2: XML to JSON\n",
    "\n",
    "Transform the original XML Films database into a JSON file (or files) following your schema.\n",
    "\n",
    "Use your favorite tool: Basic python, SAX, DOM, xml..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PScrJhXx5can"
   },
   "source": [
    "Solution using `DOM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pQGcL-JP5Uha"
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "from xml.dom.minidom import parse\n",
    "import copy\n",
    "\n",
    "dom = parse(\"films.xml\")\n",
    "filmTextElems = [\"TITRE\", \"GENRE\", \"PAYS\", \"RESUME\"]\n",
    "artistTextElems = [\"ACTNOM\", \"ACTPNOM\", \"ANNEENAISS\"]\n",
    "roleTextElements = [\"NOM\", \"PRENOM\", \"INTITULE\"]\n",
    "\n",
    "def getText(node):\n",
    "    try:\n",
    "        return node.childNodes[0].data\n",
    "    except Exception as e:  \n",
    "        print(f'Problems getText with node {node.tagName}')\n",
    "        raise e\n",
    "\n",
    "def getAttributes(node):\n",
    "    res = {}\n",
    "    if node.hasAttributes():\n",
    "        for k, v in node.attributes.items():\n",
    "            res[k] = v\n",
    "    return res\n",
    "\n",
    "def getTextElements(node, elements):\n",
    "    res = {}\n",
    "    for elem in elements:\n",
    "        for t in node.getElementsByTagName(elem):\n",
    "            if t.hasChildNodes():\n",
    "                res[elem] = getText(t)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# Get films\n",
    "films = []\n",
    "for f in dom.getElementsByTagName(\"FILM\"):\n",
    "    film = getTextElements(f, filmTextElems)\n",
    "    film.update(getAttributes(f))\n",
    "\n",
    "    # Read MES\n",
    "    for m in f.getElementsByTagName('MES'):\n",
    "        film[\"MES\"] = m.getAttribute('id_mes')\n",
    "    \n",
    "    # Read ROLES\n",
    "    roles = []\n",
    "    for r in f.getElementsByTagName('ROLE'):\n",
    "        roles.append(getTextElements(r, roleTextElements))\n",
    "    \n",
    "    film.update({'ROLES':  copy.deepcopy(roles)})\n",
    "\n",
    "    # I created a special TITRE. I have to create it\n",
    "    film[\"TITRE\"] = {\n",
    "        \"title\": film[\"TITRE\"],\n",
    "        \"lang\": \"@fr\",\n",
    "        \"note\": \"Lorem ipsum\"\n",
    "    }\n",
    "\n",
    "    films.append(film)\n",
    "\n",
    "\n",
    "# Get artists\n",
    "artists = []\n",
    "for a in dom.getElementsByTagName(\"ARTISTE\"):\n",
    "    artist = getTextElements(a, artistTextElems)\n",
    "    artist.update(getAttributes(a))\n",
    "    artists.append(artist)\n",
    "\n",
    "\n",
    "\n",
    "FILMS = {'arrArtistes':artists , 'arrFilms':films}\n",
    "\n",
    "# Save\n",
    "json.dump(FILMS, open('films.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiS7o5SC_PPS"
   },
   "source": [
    "# Excercise 3: Validate the data\n",
    "\n",
    "Validate the FILMS dataset you just created with the JSON schema you created using `jsonschema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flV45W4m_ZJt",
    "outputId": "cae5ddd5-2bb7-4960-d2e5-d6f8cba8c948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is valid!\n"
     ]
    }
   ],
   "source": [
    "schema_store = {\n",
    "    schemaRole['$id']: schemaRole,\n",
    "    schemaFilmsObject['$id'] : schemaFilmsObject,\n",
    "    schemaArtistObject['$id'] : schemaArtistObject,\n",
    "    schemaFilmsDatabase['$id']: schemaFilmsDatabase\n",
    "}\n",
    "\n",
    "# Create a resolver to work with local files and avoid fetching URLs\n",
    "resolver = RefResolver.from_schema(schemaFilmsDatabase, store=schema_store)\n",
    "\n",
    "validator = Draft7Validator(schemaFilmsDatabase, resolver=resolver)\n",
    "\n",
    "try:\n",
    "    validator.validate(FILMS)\n",
    "    print(\"File is valid!\")\n",
    "except Exception as e:\n",
    "    print(\"File was not validated correctly. Here are the catched exceptions\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CpQavsnBi0p"
   },
   "source": [
    "# Excercise 4: JSONPath to query the dataset\n",
    "\n",
    "We are going to redo some of the queries we have worked on but using this new tool, **JSONPath**.\n",
    "The implementation for Python we are going to use is called `jsonpath-ng`.\n",
    "\n",
    "\n",
    "`jsonpath-ng` PyPi site: https://pypi.org/project/jsonpath-ng/\n",
    "\n",
    "\n",
    "Some documentation about **JSONPath** comparing it to **XPath**: https://goessner.net/articles/JsonPath/\n",
    "\n",
    "\n",
    "Here is a nice documentation explaining how JSONPath works, but be careful because the implementation is for Java: https://github.com/json-path/JsonPath\n",
    "\n",
    "\n",
    "This blog also has some documentation and examples using Python and the library `jsonpath-ng`:\n",
    "https://blogboard.io/blog/knowledge/jsonpath-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonpath-ng in /home/lucas/Documents/python_envs/venv/lib/python3.8/site-packages (1.5.3)\r\n",
      "Requirement already satisfied: six in /home/lucas/Documents/python_envs/venv/lib/python3.8/site-packages (from jsonpath-ng) (1.16.0)\r\n",
      "Requirement already satisfied: ply in /home/lucas/Documents/python_envs/venv/lib/python3.8/site-packages (from jsonpath-ng) (3.11)\r\n",
      "Requirement already satisfied: decorator in /home/lucas/Documents/python_envs/venv/lib/python3.8/site-packages (from jsonpath-ng) (5.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonpath-ng\n",
    "from jsonpath_ng.ext import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get all the titles\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Vertigo', 'Alien', 'Titanic', 'Sacrifice', 'Volte/Face', 'Sleepy Hollow', 'American Beauty', 'Impitoyable', 'Gladiator', 'Blade Runner', 'Piège de cristal', '58 minutes pour vivre', 'Van Gogh', 'Seven', \"L'armée des douze singes\", 'Le nom de la rose', 'Pulp fiction', 'Mary à tout prix', 'Terminator', 'Les dents de la mer', 'Le silence des agneaux', \"Le prince d'Egypte\", 'Godzilla', 'Matrix', 'Mission: Impossible', 'Kagemusha', 'Les pleins pouvoirs', 'Le gendarme et les extra-terrestres', 'Les frères pétards', 'Le monde perdu', 'Rain Man', 'Top Gun', 'Les bronzés font du ski', 'MICROCOSMOS', 'Psychose', 'Le retour du Jedi', 'Les oiseaux', 'Reservoir dogs', 'Eyes Wide Shut', 'Shining', 'Pas de printemps pour Marnie', 'Fenêtre sur cour', 'La mort aux trousses', \"Jeanne d'Arc\", 'Le cinquième élément', 'Léon', 'Nikita', 'Le grand bleu']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Get all the titles\n",
    "'''\n",
    "jsonpath_expr = parse('$.arrFilms[:].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(\"Get all the titles\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "Now try to do the original queries in TD1 on the FILMS dataset using **JSONPath**.\n",
    "\n",
    "If you find it two hard to do a query on pure JSONPath, you can mix JSONPath and pure Python using the results of a JSONPath query. Nevertheless remember that this would not be directly applicable to other JSONPath implementations, specially in other languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Get all the titles\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Vertigo', 'Alien', 'Titanic', 'Sacrifice', 'Volte/Face', 'Sleepy Hollow', 'American Beauty', 'Impitoyable', 'Gladiator', 'Blade Runner', 'Piège de cristal', '58 minutes pour vivre', 'Van Gogh', 'Seven', \"L'armée des douze singes\", 'Le nom de la rose', 'Pulp fiction', 'Mary à tout prix', 'Terminator', 'Les dents de la mer', 'Le silence des agneaux', \"Le prince d'Egypte\", 'Godzilla', 'Matrix', 'Mission: Impossible', 'Kagemusha', 'Les pleins pouvoirs', 'Le gendarme et les extra-terrestres', 'Les frères pétards', 'Le monde perdu', 'Rain Man', 'Top Gun', 'Les bronzés font du ski', 'MICROCOSMOS', 'Psychose', 'Le retour du Jedi', 'Les oiseaux', 'Reservoir dogs', 'Eyes Wide Shut', 'Shining', 'Pas de printemps pour Marnie', 'Fenêtre sur cour', 'La mort aux trousses', \"Jeanne d'Arc\", 'Le cinquième élément', 'Léon', 'Nikita', 'Le grand bleu']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"1. Get all the titles\"\n",
    "\n",
    "jsonpath_expr = parse('$.arrFilms[:].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Get all the titles of films from 1980\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Kagemusha', 'Shining']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"2. Get all the titles of films from 1980\"\n",
    "\n",
    "year = 1980\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.Annee={year})].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_title = \"3. Alien abstract\"\n",
    "\n",
    "\n",
    "\n",
    "title = \"Alien\"\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.TITRE.title == \"{title}\")].RESUME')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Films with Bruce Willis\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Piège de cristal', '58 minutes pour vivre', \"L'armée des douze singes\", 'Pulp fiction', 'Le cinquième élément']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"4. Films with Bruce Willis\"\n",
    "\n",
    "\n",
    "name, surname = \"Bruce\", \"Willis\"\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.ROLES[?(PRENOM == \"{name}\" & NOM == \"{surname}\")])].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Films with a RESUME\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Vertigo', 'Alien', 'Titanic', 'Volte/Face', 'Sleepy Hollow', 'American Beauty', 'Impitoyable', 'Gladiator', 'Blade Runner', 'Piège de cristal', '58 minutes pour vivre', 'Van Gogh', 'Seven', 'Le nom de la rose', 'Pulp fiction', 'Mary à tout prix', 'Terminator', 'Les dents de la mer', 'Le silence des agneaux', 'Godzilla', 'Matrix', 'Mission: Impossible', 'Kagemusha', 'Les pleins pouvoirs', 'Rain Man', 'Top Gun', 'Les bronzés font du ski', 'MICROCOSMOS', 'Psychose', 'Le retour du Jedi', 'Les oiseaux', 'Reservoir dogs', 'Eyes Wide Shut', 'Shining', 'Pas de printemps pour Marnie', 'Fenêtre sur cour', 'La mort aux trousses', 'Le cinquième élément', 'Léon', 'Nikita', 'Le grand bleu']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"5. Films with a RESUME\"\n",
    "\n",
    "\n",
    "tag = \"RESUME\"\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.{tag})].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Films without a RESUME\n",
      "\n",
      "------------------------------\n",
      "\n",
      "{\"Le prince d'Egypte\", \"L'armée des douze singes\", \"Jeanne d'Arc\", 'Le monde perdu', 'Sacrifice', 'Les frères pétards', 'Le gendarme et les extra-terrestres'}\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"6. Films without a RESUME\"\n",
    "\n",
    "# This one might be a little harder than before, as negations are not implemented in this library\n",
    "\n",
    "\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.RESUME)].TITRE.title')\n",
    "with_resume = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[:].TITRE.title')\n",
    "all_titles = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(set(all_titles).difference(set(with_resume)))\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Films older than 30 years\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Vertigo', 'Alien', 'Sacrifice', 'Blade Runner', 'Piège de cristal', '58 minutes pour vivre', 'Van Gogh', 'Le nom de la rose', 'Terminator', 'Les dents de la mer', 'Le silence des agneaux', 'Kagemusha', 'Le gendarme et les extra-terrestres', 'Les frères pétards', 'Rain Man', 'Top Gun', 'Les bronzés font du ski', 'Psychose', 'Le retour du Jedi', 'Les oiseaux', 'Shining', 'Pas de printemps pour Marnie', 'Fenêtre sur cour', 'La mort aux trousses', 'Nikita', 'Le grand bleu']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"7. Films older than 30 years\"\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "year_dif = 30\n",
    "year_now = date.today().year\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.Annee<{year_now-year_dif})].TITRE.title')\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role of Harvey Keitel in Reservoir Dogs\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Mr. White/Larry']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"8. Role of Harvey Keitel in Reservoir Dogs\"\n",
    "\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.TITRE.title =~ \"Reservoir dogs\")].ROLES[?(@.PRENOM == \"Harvey\" & @.NOM == \"Keitel\")].INTITULE')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. Last film in database\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Le grand bleu']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"9. Last film in database\"\n",
    "\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[-1].TITRE.title')\n",
    "\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. Film preceding The Shining\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Eyes Wide Shut\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"10. Film preceding The Shining\"\n",
    "\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[?(@.TITRE.title =~ \"Shining\")]')\n",
    "film = [match for match in jsonpath_expr.find(FILMS)][0]\n",
    "film_idx = film.path.index\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[:].TITRE.title')\n",
    "all_titles = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "result = all_titles[film_idx-1]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11. Director of Vertigo\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[{'ACTNOM': 'Hitchcock', 'ACTPNOM': 'Alfred', 'ANNEENAISS': '1899', 'id_art': '_3'}]\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"11. Director of Vertigo\"\n",
    "\n",
    "jsonpath_expr_id_mes = parse('$.arrFilms[?( @.TITRE.title =~ \"Vertigo\") ].MES')\n",
    "key_id = [match.value for match in jsonpath_expr_id_mes.find(FILMS)][0]\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrArtistes[?( @.id_art ==  {key_id})]')\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12. Titles with an S\n",
      "\n",
      "------------------------------\n",
      "\n",
      "['Sacrifice', 'Sleepy Hollow', 'Seven', 'MICROCOSMOS', 'Eyes Wide Shut', 'Shining']\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"12. Titles with an S\"\n",
    "\n",
    "\n",
    "jsonpath_expr = parse(f'$.arrFilms[?( @.TITRE.title =~  \"S\" )].TITRE.title')\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13. Nodes with three descendants\n",
      "\n",
      "------------------------------\n",
      "\n",
      "{'ACTNOM': 'Weaver', 'ACTPNOM': 'Sigourney', 'id_art': '_5'}\n",
      "******************************\n",
      "{'ACTNOM': 'Winslett', 'ACTPNOM': 'Kate', 'id_art': '_8'}\n",
      "******************************\n",
      "{'ACTNOM': 'Depp', 'ACTPNOM': 'Johnny', 'id_art': '_14'}\n",
      "******************************\n",
      "{'ACTNOM': 'Novak', 'ACTPNOM': 'Kim', 'id_art': '_16'}\n",
      "******************************\n",
      "{'ACTNOM': 'Mendes', 'ACTPNOM': 'Sam', 'id_art': '_17'}\n",
      "******************************\n",
      "{'ACTNOM': 'Spacey', 'ACTPNOM': 'Kevin', 'id_art': '_18'}\n",
      "******************************\n",
      "{'ACTNOM': 'Bening', 'ACTPNOM': 'Anette', 'id_art': '_19'}\n",
      "******************************\n",
      "{'ACTNOM': 'Hackman', 'ACTPNOM': 'Gene', 'id_art': '_21'}\n",
      "******************************\n",
      "{'ACTNOM': 'Freeman', 'ACTPNOM': 'Morgan', 'id_art': '_22'}\n",
      "******************************\n",
      "{'ACTNOM': 'Crowe', 'ACTPNOM': 'Russell', 'id_art': '_23'}\n",
      "******************************\n",
      "{'ACTNOM': 'Hauer', 'ACTPNOM': 'Rutger', 'id_art': '_25'}\n",
      "******************************\n",
      "{'ACTNOM': 'McTierman', 'ACTPNOM': 'John', 'id_art': '_26'}\n",
      "******************************\n",
      "{'ACTNOM': 'Harlin', 'ACTPNOM': 'Renny', 'id_art': '_28'}\n",
      "******************************\n",
      "{'ACTNOM': 'Dutronc', 'ACTPNOM': 'Jacques', 'id_art': '_30'}\n",
      "******************************\n",
      "{'ACTNOM': 'Fincher', 'ACTPNOM': 'David', 'id_art': '_31'}\n",
      "******************************\n",
      "{'ACTNOM': 'Pitt', 'ACTPNOM': 'Brad', 'id_art': '_32'}\n",
      "******************************\n",
      "{'ACTNOM': 'Gilliam', 'ACTPNOM': 'Terry', 'id_art': '_33'}\n",
      "******************************\n",
      "{'ACTNOM': 'Annaud', 'ACTPNOM': 'Jean-Jacques', 'id_art': '_34'}\n",
      "******************************\n",
      "{'ACTNOM': 'Slater', 'ACTPNOM': 'Christian', 'id_art': '_36'}\n",
      "******************************\n",
      "{'ACTNOM': 'Tarantino', 'ACTPNOM': 'Quentin', 'id_art': '_37'}\n",
      "******************************\n",
      "{'ACTNOM': 'Jackson', 'ACTPNOM': 'Samuel L.', 'id_art': '_38'}\n",
      "******************************\n",
      "{'ACTNOM': 'Thurman', 'ACTPNOM': 'Uma', 'id_art': '_40'}\n",
      "******************************\n",
      "{'ACTNOM': 'Farrelly', 'ACTPNOM': 'Bobby', 'id_art': '_41'}\n",
      "******************************\n",
      "{'ACTNOM': 'Diaz', 'ACTPNOM': 'Cameron', 'id_art': '_42'}\n",
      "******************************\n",
      "{'ACTNOM': 'Dillon', 'ACTPNOM': 'Mat', 'id_art': '_43'}\n",
      "******************************\n",
      "{'ACTNOM': 'Schwartzenegger', 'ACTPNOM': 'Arnold', 'id_art': '_44'}\n",
      "******************************\n",
      "{'ACTNOM': 'Sheider', 'ACTPNOM': 'Roy', 'id_art': '_46'}\n",
      "******************************\n",
      "{'ACTNOM': 'Shaw', 'ACTPNOM': 'Robert', 'id_art': '_47'}\n",
      "******************************\n",
      "{'ACTNOM': 'Dreyfus', 'ACTPNOM': 'Richard', 'id_art': '_48'}\n",
      "******************************\n",
      "{'ACTNOM': 'Chapman', 'ACTPNOM': 'Brenda', 'id_art': '_52'}\n",
      "******************************\n",
      "{'ACTNOM': 'Linney', 'ACTPNOM': 'Laura', 'id_art': '_70'}\n",
      "******************************\n",
      "{'ACTNOM': 'Girault', 'ACTPNOM': 'Jean', 'id_art': '_71'}\n",
      "******************************\n",
      "{'ACTNOM': 'Palud', 'ACTPNOM': 'Hervé', 'id_art': '_74'}\n",
      "******************************\n",
      "{'ACTNOM': 'Pernnou', 'ACTPNOM': 'Marie', 'id_art': '_87'}\n",
      "******************************\n",
      "{'ACTNOM': 'Marquand', 'ACTPNOM': 'Richard', 'id_art': '_91'}\n",
      "******************************\n",
      "{'ACTNOM': 'Hamill', 'ACTPNOM': 'Mark', 'id_art': '_92'}\n",
      "******************************\n",
      "{'ACTNOM': 'Fisher', 'ACTPNOM': 'Carrie', 'id_art': '_93'}\n",
      "******************************\n",
      "{'ACTNOM': 'Taylor', 'ACTPNOM': 'Rod', 'id_art': '_94'}\n",
      "******************************\n",
      "{'ACTNOM': 'Saint', 'ACTPNOM': 'Eva Marie', 'id_art': '_106'}\n",
      "******************************\n",
      "{'ACTNOM': 'Portman', 'ACTPNOM': 'Natalie', 'id_art': '_118'}\n",
      "******************************\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"13. Nodes with three descendants\"\n",
    "\n",
    "\n",
    "nbDesc = 3\n",
    "\n",
    "jsonpath_expr = parse(f'$.*[?( @.`len` == {nbDesc} )]')\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "for r in result:\n",
    "    print(r)\n",
    "    print(\"*\"*30)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14. Nodes whose name (tag) contains TU\n",
      "\n",
      "------------------------------\n",
      "\n",
      "{'INTITULE': 'John Ferguson'}\n",
      "{'INTITULE': 'Madeleine Elster'}\n",
      "{'INTITULE': 'Ripley'}\n",
      "{'INTITULE': 'Rose DeWitt Bukater'}\n",
      "{'INTITULE': 'Jack Dawson'}\n",
      "{'INTITULE': 'Sean Archer/Castor Troy'}\n",
      "{'INTITULE': 'Castor Troy/Sean Archer'}\n",
      "{'INTITULE': 'Constable Ichabod Crane'}\n",
      "{'INTITULE': 'Katrina Anne Van Tassel'}\n",
      "{'INTITULE': 'Le cavalier'}\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_title = \"14. Nodes whose name (tag) contains TU\"\n",
    "\n",
    "# This is again not easy to do. My solution does not work for some tags\n",
    "\n",
    "\n",
    "pattern = \"TU\"\n",
    "\n",
    "jsonpath_expr = parse('$..*')\n",
    "result = [match.value for match in jsonpath_expr.find(FILMS)]\n",
    "\n",
    "# Get everything, then \"flatten\"\n",
    "\n",
    "dicts = [x for x in result if isinstance(x, dict)]\n",
    "tosee = list(filter(lambda r: isinstance(r, list), result))\n",
    "\n",
    "while tosee:\n",
    "    a = tosee.pop(0)\n",
    "    if isinstance(a, dict):\n",
    "        dicts.append(a)\n",
    "    elif isinstance(a, list):\n",
    "        tosee.extend(a)\n",
    "\n",
    "final = []\n",
    "        \n",
    "for d in dicts:\n",
    "    for k, v in d.items():\n",
    "        if pattern in k:\n",
    "            final.append({k:v})\n",
    "        \n",
    "        \n",
    "        \n",
    "print(query_title)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "for r,_ in zip(final, range(10)):\n",
    "    print(r)\n",
    "    \n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDxi0vAZLobzU2qTtd0zJy",
   "collapsed_sections": [
    "V8i6vqq1FuQh",
    "o8CGVXpAdKwF",
    "LwMWWwBmnFTU",
    "IZ3hOsDu4t3Q",
    "YiS7o5SC_PPS"
   ],
   "include_colab_link": true,
   "name": "BDSS_2021_TD6_JSON_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
