{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDSS_2021_TD3_SAX_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V8i6vqq1FuQh",
        "hge1MvnJx-r0",
        "l_U6dtDNyaDX",
        "lCtZp-qE8ooM",
        "Z9IRkMvO98C_",
        "5nhqhzsCKC37"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7L6BwuoK6AX67Wlu10ZkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasgneccoh/BDSS_Dauphine/blob/main/BDSS_2021_TD3_SAX_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bases de données semi-structurées - TD 3\n",
        "\n",
        "Welcome to the support Python notebook for this TD. This notebook follows the paper version of the TD. \n",
        "\n",
        "The idea is to make the same exercises in a more interactive way, practice some Python and also discover or practice with Google Colab notebooks."
      ],
      "metadata": {
        "id": "M-9rovwlHP_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preambule"
      ],
      "metadata": {
        "id": "V8i6vqq1FuQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import etree\n",
        "import re\n",
        "from xml.dom.minidom import parse\n",
        "import xml.sax\n",
        "\n",
        "# Functions to work with XML files\n",
        "\n",
        "def validate_xml(xml_path:str, dtd_path:str) -> bool:\n",
        "    ''' Validate an XML file  against a DTD using the lxml library\n",
        "    '''\n",
        "    try:\n",
        "        dtd = etree.DTD(open(dtd_path))\n",
        "    except etree.DTDParseError as ed:\n",
        "        print(f\"DTDParseError: {ed}\")\n",
        "        for i, er in enumerate(ed.error_log):\n",
        "            print(f\"\\t{i}-> {er.message}, at line {er.line}\")\n",
        "        etree.clear_error_log()\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        xml_doc = etree.parse(xml_path)\n",
        "    except etree.XMLSyntaxError as e:\n",
        "        print(f\"XMLSyntaxError: {e}\")\n",
        "        for i, er in enumerate(e.error_log):\n",
        "            print(f\"\\t{i}-> {er.message}, at line {er.line}\")\n",
        "        etree.clear_error_log()\n",
        "        return False\n",
        "\n",
        "    result = dtd.validate(xml_doc)\n",
        "    if not result: print(dtd.error_log[0])\n",
        "\n",
        "    return result\n",
        "\n",
        "def write_xml_dtd_files_from_strings(xml_strings, dtd_strings, identifiers = None):\n",
        "    ''' Write a list of strings into files. This strings should be XML and DTD files\n",
        "    '''\n",
        "\n",
        "    # If single strings are given, encapsulate them in lists  \n",
        "    if all(map(lambda o: isinstance(o, str), [xml_strings, dtd_strings])):\n",
        "        xml_strings, dtd_strings = [xml_strings], [dtd_strings]\n",
        "\n",
        "    if len(xml_strings) != len(dtd_strings):\n",
        "        raise Exception(\"Different number of XML and DTD strings!\")\n",
        "\n",
        "    # If no identifiers are given, create default ones. This determines file names\n",
        "    if identifiers is None:\n",
        "        identifiers = [f\"file_{i}\" for i in range(len(xml_strings))]\n",
        "\n",
        "    try:\n",
        "        for x, d, id in zip(xml_strings, dtd_strings, identifiers):\n",
        "            xml_path, dtd_path = f\"{id}.xml\", f\"{id}.dtd\" \n",
        "            with open(xml_path,\"w\") as f:\n",
        "                f.write(x)\n",
        "            with open(dtd_path,\"w\") as f:\n",
        "                f.write(d)\n",
        "    except Exception as e:\n",
        "        print(\"Problems while writing XML and DTD files\")\n",
        "        raise e\n",
        "\n",
        "    return identifiers\n",
        "\n",
        "\n",
        "\n",
        "def test_validation(xml_string, dtd_string, validator):\n",
        "    ''' Validate an XML document against a DTD, both given as strings\n",
        "    '''\n",
        "    # Write files\n",
        "    write_xml_dtd_files_from_strings(xml_string, dtd_string, identifiers = ['temp'])\n",
        "    \n",
        "    # Validate\n",
        "    return validator(\"temp.xml\", \"temp.dtd\" )\n",
        "\n",
        "def xpath_query_xml_string(xml_string, query_string):\n",
        "    xml_path = \"xml_doc.xml\"\n",
        "    with open(xml_path, \"w\") as f:\n",
        "        # Remove all whitespaces to keep the 'real' text of each node\n",
        "        f.write(re.sub(\">[\\s|\\n]*<\", \"><\", xml_string))\n",
        "        f.close()\n",
        "    xml_doc = etree.parse(xml_path)\n",
        "    query = etree.XPath(query_string)\n",
        "    return query(xml_doc)\n",
        "\n",
        "def xpath_query_xml_file(xml_path, query_string):\n",
        "    xml_doc = etree.parse(xml_path)\n",
        "    query = etree.XPath(query_string)\n",
        "    return query(xml_doc)\n",
        "\n",
        "\n",
        "def print_xpath_query_results(results):\n",
        "    print(f\"Total results: {len(results)}\")\n",
        "    print(\"*\"*20 + \"\\n\")\n",
        "    for e in results:\n",
        "        try:        \n",
        "            print(f\"node tag: {e.tag}\")\n",
        "            print(f\"node text: *{e.text}*\")\n",
        "            print(', '.join([f\"{k} = {v}\"for k, v in e.items()]))\n",
        "            print(\"-\"*20)\n",
        "        except:\n",
        "            print(\"--Except\")\n",
        "            print(e)\n"
      ],
      "metadata": {
        "id": "SwLF3qxcFmqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAX\n"
      ],
      "metadata": {
        "id": "hge1MvnJx-r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Print only certain elements"
      ],
      "metadata": {
        "id": "l_U6dtDNyaDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrinterContentHandler(xml.sax.ContentHandler):\n",
        "    def __init__(self, tags_to_print = None):\n",
        "        super().__init__()\n",
        "        self.tags_to_print = tags_to_print\n",
        "        \n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        if not self.tags_to_print is None and name in self.tags_to_print:\n",
        "            print(\"startElement: '\" + name + \"'\")\n",
        "            print(attrs)\n",
        "        return\n",
        "\n",
        "    def endElement(self, name):\n",
        "        return\n",
        "\n",
        "    def characters(self, content):\n",
        "        # When text is encountered\n",
        "        # print(\"Characters '\" + content + \"'\")\n",
        "        return\n",
        "\n",
        "\n",
        "tags_to_print = [\"FILM\"]\n",
        "handler = PrinterContentHandler(tags_to_print = tags_to_print)\n",
        "\n",
        "path = \"imdb_sample.xml\"\n",
        "f = open(path)\n",
        "\n",
        "xml.sax.parse(f, handler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIOY0to7yY4X",
        "outputId": "5f74a49d-2732-4e5a-94a0-36c105f6bc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n",
            "startElement: 'FILM'\n",
            "<xml.sax.xmlreader.AttributesImpl object at 0x7f341c7c8290>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Get the titles"
      ],
      "metadata": {
        "id": "lCtZp-qE8ooM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetTextInsideTag(xml.sax.ContentHandler):\n",
        "    def __init__(self, tag = None):\n",
        "        super().__init__()\n",
        "        self.tag = tag\n",
        "        self.reading = False\n",
        "        self.buffer = []\n",
        "        self.result = []\n",
        "        \n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        if not self.tag is None and name == self.tag:\n",
        "            self.reading = True\n",
        "        return\n",
        "\n",
        "\n",
        "    def endElement(self, name):\n",
        "        if self.buffer:\n",
        "            # If something was read, then add it to results\n",
        "            # before reseting the buffer\n",
        "            self.result.append(' '.join(self.buffer))\n",
        "        self.reading = False\n",
        "        self.buffer = []\n",
        "        return\n",
        "\n",
        "    def characters(self, content):\n",
        "        # When text is encountered\n",
        "        # print(\"Characters '\" + content + \"'\")\n",
        "        if self.reading: self.buffer.append(content)\n",
        "        return\n",
        "\n",
        "\n",
        "tag = \"TITRE\"\n",
        "handler = GetTextInsideTag(tag = tag)\n",
        "\n",
        "path = \"imdb_sample.xml\"\n",
        "f = open(path)\n",
        "\n",
        "xml.sax.parse(f, handler)\n",
        "\n",
        "print(handler.result)"
      ],
      "metadata": {
        "id": "PS4s356Q8mnf",
        "outputId": "2aa7b4aa-972d-4272-a817-3cd10caa5d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-feb85cbeace5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGetTextInsideTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContentHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xml' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now in dom\n",
        "memoryBefore = getMemoryInfo()[3]/1e6\n",
        "print(f\"Memory usage before parsing document with DOM: {memoryBefore}\")\n",
        "dom = parse(\"imdb_sample.xml\")\n",
        "memoryAfter = getMemoryInfo()[3]/1e6\n",
        "print(f\"Memory usage after parsing document with DOM: {memoryAfter}\")\n",
        "\n",
        "print(f\"Difference: {memoryAfter - memoryBefore}\")\n",
        "\n",
        "del dom\n",
        "\n",
        "memoryAfter = getMemoryInfo()[3]/1e6\n",
        "print(f\"Memory usage after parsing document with DOM and delete: {memoryAfter}\")\n",
        "\n",
        "# I write this function to simplify getting the value of a node that only contains text\n",
        "def getText(node):\n",
        "    return node.childNodes[0].data\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Query 1\n",
        "# La liste des titres de films.      \n",
        "\n",
        "def dom_query_1_1(dom):\n",
        "    titre=[]\n",
        "    for t in dom.getElementsByTagName(\"TITRE\"):\n",
        "        titre.append(t.childNodes[0].data)\n",
        "    return titre\n",
        "\n",
        "def dom_query_1_2(dom):\n",
        "    titles = []\n",
        "    for f in dom.getElementsByTagName(\"FILM\"):\n",
        "        for t in f.getElementsByTagName(\"TITRE\"):\n",
        "            titles.append(getText(t))\n",
        "    return titles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAEfhxplF6ts",
        "outputId": "8f03e357-fb17-4967-d5cb-98467ff8203c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage before parsing document with DOM: 842.866688\n",
            "Memory usage after parsing document with DOM: 842.665984\n",
            "Difference: -0.20070399999997335\n",
            "Memory usage after parsing document with DOM and delete: 842.665984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Get the titles of films staring some artist"
      ],
      "metadata": {
        "id": "Z9IRkMvO98C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetFilmsByArtistInCast(xml.sax.ContentHandler):\n",
        "    def __init__(self, prenom, nom):\n",
        "        super().__init__()\n",
        "        self.prenomSearch = prenom\n",
        "        self.nomSearch = nom\n",
        "\n",
        "        self.result = []\n",
        "        self.titleBuffer = []\n",
        "        self.prenomBuffer = []\n",
        "        self.nomBuffer = []\n",
        "\n",
        "        self.titleTemp = None\n",
        "        self.prenomTemp = None\n",
        "        self.nomTemp = None\n",
        "        \n",
        "        self.whereInDoc = None\n",
        "\n",
        "        self.reading = False\n",
        "        \n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        self.whereInDoc = name\n",
        "        if name in [\"PRENOM\", \"NOM\", \"TITRE\"]:\n",
        "            self.reading = True\n",
        "        return\n",
        "\n",
        "    def endElement(self, name):\n",
        "        # If we read something that we need, then get the contentn and use it\n",
        "        if name == \"TITRE\":\n",
        "            self.titleTemp = ' '.join(self.titleBuffer)\n",
        "            self.titleBuffer = []\n",
        "        if name == \"PRENOM\":\n",
        "            self.prenomTemp = ' '.join(self.prenomBuffer)\n",
        "            self.prenomBuffer = []\n",
        "        if name == \"NOM\":\n",
        "            self.nomTemp = ' '.join(self.nomBuffer)\n",
        "            self.nomBuffer = []\n",
        "\n",
        "        # If we end reading a ROLE element, we can check if it contains the \n",
        "        # artist we want\n",
        "        if name == \"ROLE\":\n",
        "            if self.prenomSearch == self.prenomTemp and self.nomSearch == self.nomTemp:\n",
        "                self.result.append(self.titleTemp)\n",
        "        self.reading = False\n",
        "        return\n",
        "\n",
        "    def characters(self, content):\n",
        "        if self.reading:\n",
        "        # If we are in TITLE, we have to save it\n",
        "            if self.whereInDoc == \"TITRE\": self.titleBuffer.append(content)\n",
        "            if self.whereInDoc == \"PRENOM\": self.prenomBuffer.append(content)\n",
        "            if self.whereInDoc == \"NOM\": self.nomBuffer.append(content)\n",
        "        return\n",
        "\n",
        "    def endDocument(self):\n",
        "        self.titleBuffer = []\n",
        "        self.prenomBuffer = []\n",
        "        self.nomBuffer = []\n",
        "\n",
        "\n",
        "prenom, nom = \"Bruce\", \"Willis\"\n",
        "handler = GetFilmsByArtistInCast(prenom = prenom, nom = nom)\n",
        "\n",
        "path = \"imdb_sample.xml\"\n",
        "f = open(path)\n",
        "\n",
        "xml.sax.parse(f, handler)\n",
        "\n",
        "print(handler.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nciaru1u-Lwi",
        "outputId": "23fda4e4-3c04-4e3e-8965-c5e810370688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Die Hard', 'Pulp Fiction', 'The Sixth Sense']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ex 1: Queries with SAX on the movie dataset\n",
        "\n",
        "Try to do some other queries using SAX.\n",
        "Compare your results (and maybe even running times!) with other tools like XPath or DOM.\n",
        "\n",
        "I suggest the queries 1 to 8, and then query 11"
      ],
      "metadata": {
        "id": "5eCeJkwzCk9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6nNRy_rTKAeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data science with text\n",
        "\n",
        "Here I want to introduce you to some more advanced topics in Data Science and Machine Learning.\n",
        "\n",
        "We will use it as an excuse to practice SAX\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Bag of words and TF-IDF**\n",
        "\n",
        "In Data Science and Machine Learning, particularly in Natural Language Processing, the objects to study are text documents. There are different ways to study them, but from a mathematical perspective we need ways of encoding such text documents into more \"vectorial\" data\n",
        "\n",
        "The question becomes: ***How do you transform a piece of text into a vector to apply your algorithms on them?***\n",
        "\n",
        "\n",
        "One very common example is sentiment analysis. The basic idea is that you want to know if some text (for example a movie review or a tweet) is positive or negative towards a subject. This can be seen as a classification problem.\n",
        "\n",
        "\n",
        "The initial approach to turn a piece of text into a vector is the Bag of Words, where you characterize a document by the words that appear in it and their frequence. A more sophisticated approach can be TF-IDF that takes into account the number of words in each document and also the relative frequence of words across documents.\n",
        "\n",
        "See this site for a detailed and simple exmplanation if you have doubts\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/\n",
        "\n",
        "\n",
        "In this excercise we will try to create such document vectors for our movie dataset using SAX as a way to read the data."
      ],
      "metadata": {
        "id": "5nhqhzsCKC37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of words\n",
        "\n",
        "We need to go through the document, get the RESUME and build a vocabulary that contains all the words present in all the RESUMEs.\n",
        "\n",
        "We do not care about every word. We will remove unecessary words using a special library\n",
        "\n",
        "We are going to optimize our code and create the bag of words as we go through the resumes"
      ],
      "metadata": {
        "id": "GCgCGY89Vf81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2.1.1 \n",
        "Write a function that given some text, it eliminates all non important words\n",
        "and returns a list of words representing the text\n",
        "We will use a library called spacy for the stop words in french and we can use\n",
        "another library called gensim to help us do some other preprocessing\n",
        "\n",
        "'''\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
        "import gensim.parsing.preprocessing as prep\n",
        "import re\n",
        "\n",
        "CUSTOM_FILTERS = [lambda x: x.lower(), lambda x: re.sub('\\W+',' ',x) ,\\\n",
        "                    prep.strip_tags, prep.strip_punctuation, \\\n",
        "                    prep.strip_punctuation2, prep.strip_multiple_whitespaces, \\\n",
        "                    prep.strip_numeric, \\\n",
        "                    prep.strip_short]\n",
        "our_prep_func = lambda x: prep.preprocess_string(x, CUSTOM_FILTERS)\n",
        "\n",
        "\n",
        "# Traiter le texte\n",
        "resume = \"Pulp Fiction décrit l'odyssée sanglante et burlesque de petits malfrats \\\n",
        "dans la jungle de Hollywood, ou s'entrecroisent les destins de deux petits \\\n",
        "tueurs, d'un dangereux gangster marié à une camée, d'un boxeur roublard, de \\\n",
        "prêteurs sur gages sadiques, d'un caïd élégant et dévoué, d'un dealer bon \\\n",
        "mari et de deux tourtereaux à la gachette facile...\"\n",
        "\n",
        "# Lets test the two approaches to see the difference\n",
        "new = [s for s in resume.split() if s not in fr_stop]\n",
        "print(new)\n",
        "\n",
        "new = [s for s in our_prep_func(resume) if s not in fr_stop]\n",
        "print(new)\n",
        "\n",
        "\n",
        "# This is the actual function\n",
        "def process_text(text, processing, stopwords = fr_stop):\n",
        "    return [s for s in processing(text) if s not in stopwords]\n",
        "\n",
        "\n",
        "print(\"Our final function\")\n",
        "new = process_text(resume, our_prep_func, fr_stop)\n",
        "print(new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3O23avnS6Ll",
        "outputId": "8eb84c75-e0c1-4ee3-c33c-9b290c6f85b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pulp', 'Fiction', 'décrit', \"l'odyssée\", 'sanglante', 'burlesque', 'petits', 'malfrats', 'jungle', 'Hollywood,', \"s'entrecroisent\", 'destins', 'petits', 'tueurs,', \"d'un\", 'dangereux', 'gangster', 'marié', 'camée,', \"d'un\", 'boxeur', 'roublard,', 'prêteurs', 'gages', 'sadiques,', \"d'un\", 'caïd', 'élégant', 'dévoué,', \"d'un\", 'dealer', 'bon', 'mari', 'tourtereaux', 'gachette', 'facile...']\n",
            "['pulp', 'fiction', 'décrit', 'odyssée', 'sanglante', 'burlesque', 'petits', 'malfrats', 'jungle', 'hollywood', 'entrecroisent', 'destins', 'petits', 'tueurs', 'dangereux', 'gangster', 'marié', 'camée', 'boxeur', 'roublard', 'prêteurs', 'gages', 'sadiques', 'caïd', 'élégant', 'dévoué', 'dealer', 'bon', 'mari', 'tourtereaux', 'gachette', 'facile']\n",
            "Our final function\n",
            "['pulp', 'fiction', 'décrit', 'odyssée', 'sanglante', 'burlesque', 'petits', 'malfrats', 'jungle', 'hollywood', 'entrecroisent', 'destins', 'petits', 'tueurs', 'dangereux', 'gangster', 'marié', 'camée', 'boxeur', 'roublard', 'prêteurs', 'gages', 'sadiques', 'caïd', 'élégant', 'dévoué', 'dealer', 'bon', 'mari', 'tourtereaux', 'gachette', 'facile']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2.1.2\n",
        "Defining the word count of a document\n",
        "Write a function that given a list of words and a vocabulary, computes the word\n",
        "count representation of the text\n",
        "The vocabulary will be represented as a dictionary containing pairs (word, index)\n",
        "where index is the position of the word in the vocabulary\n",
        "\n",
        "We will suppose that all the words are in the vocabulary\n",
        "'''\n",
        "\n",
        "def bag_of_words(tokens, vocab):\n",
        "    vector = [0]*len(vocab)\n",
        "    for s in tokens:\n",
        "        vector[vocab[s]] += 1\n",
        "    return vector\n",
        "\n",
        "\n",
        "# Test it with a simple example\n",
        "tokens = [\"test\", \"sentence\", \"test\", \"test\", \"horse\", \"sentence\"]\n",
        "vocab = {\"sentence\":0, \"horse\":1, \"test\":2}\n",
        "bow = bag_of_words(tokens, vocab)\n",
        "print(bow)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgJolpfpcrIg",
        "outputId": "4c058ebc-661d-4c9c-bfb2-f94be2d46435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2.1.3\n",
        "Expanding a vocabulary\n",
        "When we read new text, some new words might appear. We need to add them to the\n",
        "vocabulary we are considering.\n",
        "Write a function that given a vocabulary and some new text (already preprocessed),\n",
        "adds the new words to the vocabulary (if there are new words)\n",
        "'''\n",
        "\n",
        "def expand_vocab(vocab, new_tokens):\n",
        "    for s in new_tokens:\n",
        "        if not s in vocab:\n",
        "            vocab[s] = len(vocab)\n",
        "\n",
        "\n",
        "# Test\n",
        "tokens = [\"test\", \"new_word\", \"horse\", \"more_novelty\"]\n",
        "vocab = {\"sentence\":0, \"horse\":1, \"test\":2}\n",
        "expand_vocab(vocab, tokens)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip9A8zfwfkVl",
        "outputId": "a4e22c68-d594-45c1-e502-9f7411049914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence': 0, 'horse': 1, 'test': 2, 'new_word': 3, 'more_novelty': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2.1.4\n",
        "Put it all together\n",
        "Now use the functions we created and SAX to build the bag of words representation\n",
        "for all the resumes\n",
        "\n",
        "Note: We will take care of the length of the vectors later\n",
        "'''\n",
        "\n",
        "class ResumeBagOfWordsSax(xml.sax.ContentHandler):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.reading = False\n",
        "        self.vectors = {}\n",
        "        self.titleTemp = None\n",
        "        self.resumeTemp = None\n",
        "        self.buffer = []\n",
        "        self.vectorTemp = None\n",
        "        self.vocab = {}\n",
        "        self.tokensSave = {}\n",
        "        \n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        self.whereInDoc = name\n",
        "        if name in [\"TITRE\", \"RESUME\"]:\n",
        "            self.reading = True\n",
        "        return\n",
        "\n",
        "    def endElement(self, name):\n",
        "        if name == \"TITRE\":\n",
        "            # We finished reading the title, so we create the entry in the dictionary\n",
        "            self.titleTemp = ' '.join(self.buffer)\n",
        "            # If the RESUME was before, then the vector is ready\n",
        "            if not self.vectorTemp is None:\n",
        "                self.vectors[self.titleTemp] = self.vectorTemp\n",
        "            else:\n",
        "                self.vectors[self.titleTemp] = []\n",
        "\n",
        "        if name == \"RESUME\":\n",
        "            # We finished reading a RESUME. We need to create the BoW\n",
        "            self.resumeTemp = ' '.join(self.buffer)\n",
        "            # Preprocess the text\n",
        "            tokens = process_text(self.resumeTemp, our_prep_func, fr_stop)\n",
        "            # Expand the vocabulary\n",
        "            expand_vocab(self.vocab, tokens)\n",
        "            # Create the BoW vector\n",
        "            bow = bag_of_words(tokens, self.vocab)\n",
        "            # Save it\n",
        "            if not self.titleTemp is None:\n",
        "                self.vectors[self.titleTemp] = bow\n",
        "                self.tokensSave[self.titleTemp] = tokens\n",
        "            else:\n",
        "                # We haven't read the title, so we stock the vector in the \n",
        "                # temporal variable\n",
        "                self.vectorTemp = bow\n",
        "        \n",
        "        if name == \"FILM\":\n",
        "            # Restart the temporal values\n",
        "            self.titleTemp = None\n",
        "            self.resumeTemp = None\n",
        "            self.vectorTemp = None\n",
        "        self.reading = False\n",
        "        self.buffer = []\n",
        "        return\n",
        "\n",
        "    def characters(self, content):\n",
        "        if self.reading:\n",
        "            self.buffer.append(content)\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "handler = ResumeBagOfWordsSax()\n",
        "\n",
        "path = \"imdb_simple_example.xml\"\n",
        "f = open(path)\n",
        "\n",
        "xml.sax.parse(f, handler)\n",
        "\n",
        "print(*handler.vectors.items(), sep=\"\\n\")\n"
      ],
      "metadata": {
        "id": "jOHrXZgZkICh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a07d1-5b2a-4fb6-eb90-189f52b60eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Vertigo', [5, 2, 1, 4, 1, 1, 1, 1])\n",
            "('Alien', [0, 0, 0, 2, 2, 0, 0, 6, 1, 1, 2])\n",
            "('Titanic', [0, 0, 0, 4, 1, 0, 0, 3, 1, 0, 2, 2, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Lets fill the vectors with zeros to get them to the right length\n",
        "'''\n",
        "N = len(handler.vocab)\n",
        "for k, v in handler.vectors.items():\n",
        "    v += [0]*(N-len(v))\n",
        "\n",
        "print(\"New vectors after resize\")\n",
        "print(*handler.vectors.items(), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yktmPf0duqeB",
        "outputId": "9ce2c6fa-8599-4f76-de6e-8d8b029cab0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New vectors after resize\n",
            "('Vertigo', [5, 2, 1, 4, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "('Alien', [0, 0, 0, 2, 2, 0, 0, 6, 1, 1, 2, 0, 0, 0, 0])\n",
            "('Titanic', [0, 0, 0, 4, 1, 0, 0, 3, 1, 0, 2, 2, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "We can create a table to better understand each vector\n",
        "\n",
        "NOTE: This only makes sense with dummy datasets\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.DataFrame(data = handler.vectors, index = handler.vocab.keys())\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "kW-1IScsun3m",
        "outputId": "ebe31599-fbb8-422d-e654-b3ce79357c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c77a45a-0f79-4295-a61d-dccb0e5b1504\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vertigo</th>\n",
              "      <th>Alien</th>\n",
              "      <th>Titanic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bad</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>terrible</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horrible</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>very</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>super</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disappointing</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>good</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perfect</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excellent</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loved</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>great</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movie</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>but</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c77a45a-0f79-4295-a61d-dccb0e5b1504')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c77a45a-0f79-4295-a61d-dccb0e5b1504 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c77a45a-0f79-4295-a61d-dccb0e5b1504');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               Vertigo  Alien  Titanic\n",
              "bad                  5      0        0\n",
              "terrible             2      0        0\n",
              "horrible             1      0        0\n",
              "very                 4      2        4\n",
              "super                1      2        1\n",
              "disappointing        1      0        0\n",
              "not                  1      0        0\n",
              "good                 1      6        3\n",
              "perfect              0      1        1\n",
              "excellent            0      1        0\n",
              "loved                0      2        2\n",
              "great                0      0        2\n",
              "movie                0      0        1\n",
              "sad                  0      0        1\n",
              "but                  0      0        1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "Now that we have the Bag of Words for each resume, we can create the TF-IDF representations\n",
        "\n",
        "This can be done in serveral ways, and you can try the one you think is more fun\n",
        "\n",
        "\n",
        "\n",
        "*   Use plain Python\n",
        "*   Use *numpy* (vectors, vector operations)\n",
        "*   Use *pandas* (easiest way IMO)\n",
        "\n"
      ],
      "metadata": {
        "id": "xt-Q_w01qgkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rReIEPiTqf8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}